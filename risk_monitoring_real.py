"""
AI ê¸°ë°˜ ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ìŠ¤ì¼€ì¤„ë§ ë° íšŒì‚¬ ì „ìš© ëª¨ë‹ˆí„°ë§ ì¶”ê°€
24ê°œêµ­ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ with AI ë¶„ì„
"""

import os
import json
import smtplib
import logging
import hashlib
import pickle
import schedule
import sys
import re
import time
import argparse
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Set
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from dateutil import parser
from dateutil.relativedelta import relativedelta
from dataclasses import dataclass, asdict
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê·¸ ì„¤ì •
def setup_logging(log_level='INFO'):
    """Setup logging configuration"""
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(log_format))
    
    file_handler = logging.FileHandler(
        f'monitoring_{datetime.now().strftime("%Y%m%d")}.log', 
        encoding='utf-8'
    )
    file_handler.setFormatter(logging.Formatter(log_format))
    
    logger = logging.getLogger()
    logger.setLevel(getattr(logging, log_level))
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    
    return logger

logger = setup_logging(os.getenv('LOG_LEVEL', 'INFO'))

class CompanyNewsCache:
    """íšŒì‚¬ ë‰´ìŠ¤ ìºì‹œ ê´€ë¦¬ (3ì‹œê°„ ì£¼ê¸° ì²´í¬ìš©)"""
    
    def __init__(self, cache_file='company_news_cache.pkl'):
        self.cache_file = cache_file
        self.cache = self.load_cache()
        # ìµœê·¼ ì²˜ë¦¬ëœ ë‰´ìŠ¤ ëª©ë¡ ìœ ì§€ (AI ì¤‘ë³µ ì²´í¬ìš©)
        self.recent_news_file = 'company_recent_news.pkl'
        self.recent_news = self.load_recent_news()
    
    def load_cache(self) -> Set[str]:
        """ìºì‹œ ë¡œë“œ"""
        if Path(self.cache_file).exists():
            try:
                with open(self.cache_file, 'rb') as f:
                    return pickle.load(f)
            except:
                return set()
        return set()
    
    def load_recent_news(self) -> List[NewsItem]:
        """ìµœê·¼ ì²˜ë¦¬ëœ ë‰´ìŠ¤ ëª©ë¡ ë¡œë“œ"""
        if Path(self.recent_news_file).exists():
            try:
                with open(self.recent_news_file, 'rb') as f:
                    return pickle.load(f)
            except:
                return []
        return []
    
    def save_cache(self):
        """ìºì‹œ ì €ì¥"""
        with open(self.cache_file, 'wb') as f:
            pickle.dump(self.cache, f)
    
    def save_recent_news(self):
        """ìµœê·¼ ë‰´ìŠ¤ ëª©ë¡ ì €ì¥"""
        with open(self.recent_news_file, 'wb') as f:
            pickle.dump(self.recent_news, f)
    
    def is_new_news(self, news_hash: str) -> bool:
        """ìƒˆë¡œìš´ ë‰´ìŠ¤ì¸ì§€ í™•ì¸"""
        return news_hash not in self.cache
    
    def add_news(self, news_hash: str):
        """ë‰´ìŠ¤ í•´ì‹œ ì¶”ê°€"""
        self.cache.add(news_hash)
        
    def add_recent_news(self, news_item: NewsItem):
        """ìµœê·¼ ë‰´ìŠ¤ ëª©ë¡ì— ì¶”ê°€ (ìµœëŒ€ 100ê°œ ìœ ì§€)"""
        self.recent_news.append(news_item)
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        if len(self.recent_news) > 100:
            self.recent_news = self.recent_news[-100:]
    
    def get_recent_news_for_comparison(self, days: int = 7) -> List[NewsItem]:
        """ë¹„êµë¥¼ ìœ„í•œ ìµœê·¼ ë‰´ìŠ¤ ë°˜í™˜ (ê¸°ë³¸ 7ì¼)"""
        cutoff_date = datetime.now() - timedelta(days=days)
        filtered_news = []
        
        for news in self.recent_news:
            try:
                news_date = parser.parse(news.collected_at)
                if news_date >= cutoff_date:
                    filtered_news.append(news)
            except:
                # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í¬í•¨
                filtered_news.append(news)
        
        return filtered_news
    
    def clear_old_cache(self):
        """ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬ (ì„ íƒì )"""
        pass

@dataclass
class NewsItem:
    """News item data class"""
    title: str
    date: str
    source: str
    snippet: str
    link: str
    country: str
    country_code: str
    country_ko: str = ""
    thumbnail: str = ""
    search_type: str = "news"
    collected_at: str = ""
    news_hash: str = ""
    
    # AI analysis result fields
    risk_score: float = 0.0
    risk_level: str = ""
    risk_category: str = ""
    ai_summary_ko: str = ""
    ai_title_ko: str = ""  # í•œêµ­ì–´ ì œëª© ì¶”ê°€
    ai_full_translation_ko: str = ""
    is_duplicate: bool = False
    duplicate_of: str = ""
    ai_analysis_timestamp: str = ""
    is_company_news: bool = False  # íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤ ì—¬ë¶€
    
    def __post_init__(self):
        """ë‰´ìŠ¤ í•´ì‹œ ìƒì„±"""
        if not self.news_hash:
            content = f"{self.title}{self.snippet}{self.source}"
            self.news_hash = hashlib.md5(content.encode()).hexdigest()

class GeminiAnalyzer:
    """Gemini AI ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str):
        """Gemini API ì´ˆê¸°í™”"""
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash')
        logger.info("âœ… Gemini 2.0 Flash ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ë¦¬ìŠ¤í¬ ì ìˆ˜ ê¸°ì¤€
        self.risk_thresholds = {
            'HIGH': 80,
            'MEDIUM': 60,
            'LOW': 40
        }

    def evaluate_company_news_relevance(self, news_item: NewsItem, keyword: str) -> Tuple[bool, str]:
        """AI ê¸°ë°˜ íšŒì‚¬ ë‰´ìŠ¤ ê´€ë ¨ì„± í‰ê°€"""
        try:
            prompt = f"""You are evaluating if this news article is relevant for Samsung C&T's construction business risk monitoring.

News Details:
Title: {news_item.title}
Content: {news_item.snippet}
Source: {news_item.source}
Date: {news_item.date}
Search Keyword Used: {keyword}

Evaluation Criteria:
1. MUST be about Samsung C&T's construction/engineering business (not Samsung Electronics or other affiliates)
2. MUST NOT be from Korean media if it's just translating/republishing Korean news
3. MUST NOT be from Samsung's official PR channels or newsrooms
4. MUST be relevant to construction industry (projects, safety, contracts, infrastructure, mou)
5. Should focus on: accidents, project delays, legal issues, business deals, safety incidents, labor disputes

Response Format:
Relevant: (Yes/No)
Reason: (One sentence explanation)
Confidence: (High/Medium/Low)"""

            response = self.model.generate_content(prompt)
            result = response.text.strip().lower()
            
            # Parse response
            is_relevant = 'relevant: yes' in result
            
            # Extract reason for logging
            reason = "AI evaluation"
            if 'reason:' in result:
                reason_start = result.index('reason:') + 7
                reason_end = result.find('\n', reason_start)
                if reason_end == -1:
                    reason = result[reason_start:].strip()
                else:
                    reason = result[reason_start:reason_end].strip()
            
            return is_relevant, reason
            
        except Exception as e:
            logger.error(f"AI relevance check error: {e}")
            # Fallback to include if AI fails
            return True, "AI evaluation failed - including by default"

    def remove_duplicates(self, news_list: List[NewsItem]) -> List[NewsItem]:
        """AI ê¸°ë°˜ ì¤‘ë³µ ë‰´ìŠ¤ ì œê±°"""
        logger.info("ğŸ” AI ê¸°ë°˜ ì¤‘ë³µ ë‰´ìŠ¤ ì œê±° ì‹œì‘...")
        
        if not news_list:
            return []
        
        unique_news = []
        duplicate_count = 0
        
        country_news = {}
        for news in news_list:
            country = news.country
            if country not in country_news:
                country_news[country] = []
            country_news[country].append(news)
        
        for country, items in country_news.items():
            if not items:
                continue
            
            items.sort(key=lambda x: x.date, reverse=True)
            unique_news.append(items[0])
            
            for i in range(1, len(items)):
                candidate = items[i]
                is_duplicate = False
                duplicate_of = None
                
                country_unique = [n for n in unique_news if n.country == country]
                
                if country_unique:
                    is_duplicate, duplicate_of = self._check_duplicate_with_ai(
                        candidate, 
                        country_unique[-min(10, len(country_unique)):]
                    )
                
                if not is_duplicate:
                    unique_news.append(candidate)
                else:
                    duplicate_count += 1
                    candidate.is_duplicate = True
                    candidate.duplicate_of = duplicate_of or ""
                    logger.debug(f"  - ì¤‘ë³µ ì œê±°: {candidate.title[:50]}...")
            
            original_count = len(items)
            final_count = len([n for n in unique_news if n.country == country])
            logger.info(f"  - {country}: {original_count}ê±´ â†’ {final_count}ê±´")
        
        logger.info(f"âœ… AI ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(news_list)}ê±´ â†’ {len(unique_news)}ê±´")
        return unique_news
    
    def _check_duplicate_with_ai(self, candidate: NewsItem, existing_news: List[NewsItem]) -> Tuple[bool, Optional[str]]:
        """AIë¥¼ ì‚¬ìš©í•œ ì¤‘ë³µ ì²´í¬"""
        try:
            prompt = f"""You are a news deduplication expert. Analyze if the candidate news is reporting the EXACT SAME INCIDENT as any existing news.

[CANDIDATE NEWS]
Title: {candidate.title}
Content: {candidate.snippet}
Date: {candidate.date}
Source: {candidate.source}

[EXISTING NEWS LIST]
"""
            for idx, news in enumerate(existing_news, 1):
                prompt += f"""
{idx}.
Title: {news.title}
Content: {news.snippet}
Date: {news.date}
Source: {news.source}
"""
            
            prompt += """

RESPONSE FORMAT:
IsDuplicate: (Yes/No)
DuplicateNumber: (1-10, or 0 if not duplicate)
Reason: (Brief explanation)"""
            
            response = self.model.generate_content(prompt)
            result = response.text.strip()
            
            is_duplicate = False
            duplicate_idx = 0
            
            lines = result.split('\n')
            for line in lines:
                line_lower = line.lower()
                if 'isduplicate:' in line_lower:
                    is_duplicate = 'yes' in line_lower and 'no' not in line_lower
                elif 'duplicatenumber:' in line_lower:
                    match = re.search(r'\d+', line)
                    if match:
                        duplicate_idx = int(match.group())
            
            if is_duplicate and 1 <= duplicate_idx <= len(existing_news):
                return True, existing_news[duplicate_idx - 1].link
            
            return False, None
            
        except Exception as e:
            logger.error(f"AI duplicate check error: {e}")
            return False, None

    def analyze_risk_batch(self, news_list: List[NewsItem], batch_size: int = 5) -> List[NewsItem]:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¦¬ìŠ¤í¬ ë¶„ì„ - ì¡°ì •ëœ ì„ê³„ê°’ ì ìš©"""
        logger.info(f"ğŸ¤– AI ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹œì‘ ({len(news_list)}ê±´)...")
        
        filtered_list = news_list
        analyzed_news = []
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for i in range(0, len(filtered_list), batch_size):
            batch = filtered_list[i:i+batch_size]
            prompt = self._create_risk_analysis_prompt(batch)
            
            try:
                response = self.model.generate_content(prompt)
                results = self._parse_risk_response(response.text, batch)
                
                # íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤ ê°€ì¤‘ì¹˜
                for news in results:
                    if news.country_code in ["samsung", "global_samsung"]:
                        news.is_company_news = True
                        # ê°€ì¤‘ì¹˜ 10ì  ì¶”ê°€
                        news.risk_score = min(100, news.risk_score + 10)
                        
                        # ë¦¬ìŠ¤í¬ ë ˆë²¨ ì¬ê³„ì‚° (ì¡°ì •ëœ ì„ê³„ê°’ ì ìš©)
                        if news.risk_score >= self.risk_thresholds['HIGH']:  # 80 ì´ìƒ
                            news.risk_level = 'HIGH'
                        elif news.risk_score >= self.risk_thresholds['MEDIUM']:  # 60 ì´ìƒ
                            news.risk_level = 'MEDIUM'
                        elif news.risk_score >= self.risk_thresholds['LOW']:  # 40 ì´ìƒ
                            news.risk_level = 'LOW'
                        else:
                            news.risk_level = 'VERY_LOW'  # 40 ë¯¸ë§Œ
                        
                        logger.debug(f"  íšŒì‚¬ ë‰´ìŠ¤: {news.title[:50]}... -> {news.risk_level} ({news.risk_score:.0f}ì )")
                
                analyzed_news.extend(results)
                time.sleep(1)
                logger.info(f"  - ë¶„ì„ ì§„í–‰: {min(i+batch_size, len(filtered_list))}/{len(filtered_list)}")
                
            except Exception as e:
                logger.error(f"âŒ AI ë¶„ì„ ì˜¤ë¥˜: {e}")
                for news in batch:
                    news.risk_score = 0
                    news.risk_level = "VERY_LOW"
                analyzed_news.extend(batch)
        
        # ì ìˆ˜ ë¶„í¬ í†µê³„ (ë””ë²„ê¹…ìš©)
        score_distribution = {
            '0-40 (ì œì™¸)': 0,
            '40-60 (LOW)': 0,
            '60-80 (MEDIUM)': 0,
            '80-100 (HIGH)': 0
        }
        
        for n in analyzed_news:
            if n.risk_score < 40:
                score_distribution['0-40 (ì œì™¸)'] += 1
            elif n.risk_score < 60:
                score_distribution['40-60 (LOW)'] += 1
            elif n.risk_score < 80:
                score_distribution['60-80 (MEDIUM)'] += 1
            else:
                score_distribution['80-100 (HIGH)'] += 1
        
        logger.info(f"ğŸ“Š AI í‰ê°€ ì ìˆ˜ ë¶„í¬:")
        for range_key, count in score_distribution.items():
            logger.info(f"  {range_key}: {count}ê±´")
        
        # í•„í„°ë§: LOW(40ì ) ì´ìƒë§Œ í¬í•¨
        filtered_news = []
        for n in analyzed_news:
            if 'OPPORTUNITY:' in n.risk_category:
                # ê¸°íšŒëŠ” 60ì  ì´ìƒë§Œ (ì¤‘ìš”í•œ ê¸°íšŒë§Œ)
                if n.risk_score >= 60:
                    filtered_news.append(n)
            else:
                # ë¦¬ìŠ¤í¬ëŠ” 40ì  ì´ìƒë§Œ í¬í•¨
                if n.risk_score >= self.risk_thresholds['LOW']:  # 40ì 
                    filtered_news.append(n)
        
        # í•„í„°ë§ ê²°ê³¼ ë¡œê¹…
        logger.info(f"ğŸ“Š í•„í„°ë§ ê²°ê³¼:")
        logger.info(f"  - ë¶„ì„ ì „ì²´: {len(analyzed_news)}ê±´")
        logger.info(f"  - í•„í„°ë§ í›„: {len(filtered_news)}ê±´ (í¬í•¨ë¥ : {(len(filtered_news)/max(len(analyzed_news), 1)*100):.1f}%)")
        logger.info(f"  - HIGH (80+): {sum(1 for n in filtered_news if n.risk_level == 'HIGH')}ê±´")
        logger.info(f"  - MEDIUM (60-79): {sum(1 for n in filtered_news if n.risk_level == 'MEDIUM')}ê±´")
        logger.info(f"  - LOW (40-59): {sum(1 for n in filtered_news if n.risk_level == 'LOW')}ê±´")
        
        return filtered_news
    
    def _create_risk_analysis_prompt(self, news_batch: List[NewsItem]) -> str:
        """ë¦¬ìŠ¤í¬ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± - ì—„ê²©í•œ ê¸°ì¤€ ì ìš©"""
        prompt = """You are a risk and opportunity analysis expert for a global construction company.
    Please analyze the following news articles with BALANCED CRITERIA.

    SCORING GUIDELINES:
    - Use the full 0-100 range appropriately
    - Most routine news should score 20-40 (LOW but worth monitoring)
    - Significant events should score 40-70 (MEDIUM attention needed)  
    - Only truly critical events should score 70+ (HIGH immediate action)
    - Don't be overly conservative - if it's newsworthy for the company, give it at least 20 points

    EVALUATION CRITERIA FOR NEGATIVE EVENTS (Risks):
    1. Business Impact (0-40 points) - ONLY assign points if:
    - CONFIRMED project cancellation or major delay (>6 months): 30-40 points
    - VERIFIED financial loss over $10 million: 25-35 points
    - ACTIVE legal proceedings with potential >$5M liability: 20-30 points
    - Minor delays or speculative impacts: 0-10 points only
    
    2. Reputation Impact (0-30 points) - ONLY assign points if:
    - International media coverage with company name in headline: 20-30 points
    - Major scandal with evidence of wrongdoing: 15-25 points
    - Regional/local coverage only: 0-10 points
    - Routine business disputes: 0-5 points
    
    3. Employee Safety/Harm (0-30 points) - ONLY assign points if:
    - Confirmed fatalities at company sites: 25-30 points
    - Multiple serious injuries (hospitalization required): 15-25 points
    - Minor injuries or potential threats: 0-10 points
    - General area risks without direct impact: 0-5 points

    EVALUATION CRITERIA FOR POSITIVE EVENTS (Opportunities):
    1. Business Value (0-40 points) - ONLY assign points if:
    - Confirmed contract over $1 billion: 35-40 points
    - Confirmed contract $500M-$1B: 25-35 points
    - Strategic partnership with Fortune 500: 20-30 points
    - Smaller deals or preliminary discussions: 0-15 points
    
    2. Strategic Impact (0-30 points) - ONLY assign points if:
    - Entry into new major market/country: 20-30 points
    - Game-changing technology acquisition: 15-25 points
    - Routine expansion or minor partnerships: 0-10 points
    
    3. Brand Enhancement (0-30 points) - ONLY assign points if:
    - Global award or #1 ranking: 20-30 points
    - Major sustainability achievement: 15-25 points
    - Regional recognition: 0-10 points

    SPECIAL WEIGHTS (apply ONLY when clearly applicable):
    - Direct mention of Samsung C&T or Samsung Construction: +15 points (reduced from +20)
    - For Risks: Confirmed deaths of 20+ people: +25 points (increased threshold)
    - For Risks: National emergency officially declared: +20 points
    - For Opportunities: Confirmed contracts over $2 billion: +25 points (increased threshold)

    FILTERING RULES:
    - If total score is below 40, generally classify as LOW and consider filtering out
    - Only truly significant events should score above 60
    - Reserve 85+ scores for catastrophic events or transformational opportunities

    Note: Be skeptical of sensationalized headlines. Look for concrete facts and confirmed information.

    For each news item, respond in the following format:
    [News Number]
    EventType: (Risk/Opportunity)
    RiskScore: (0-100, be conservative)
    OpportunityScore: (0-100, be conservative)
    RiskCategory: (category name)
    Reasoning: (Explain why score is low/medium/high)
    KeyPoint: (One sentence summary)

    NEWS LIST:
    """
        
        for idx, news in enumerate(news_batch):
            prompt += f"\n[{idx+1}]\n"
            prompt += f"Title: {news.title}\n"
            prompt += f"Country: {news.country}\n"
            prompt += f"Source: {news.source}\n"
            prompt += f"Content: {news.snippet}\n"
            prompt += f"Date: {news.date}\n"
        
        return prompt
    
    def _parse_risk_response(self, response_text: str, news_batch: List[NewsItem]) -> List[NewsItem]:
        """AI ì‘ë‹µ íŒŒì‹± - ì¡°ì •ëœ ì„ê³„ê°’ ì ìš©"""
        results = []
        sections = response_text.split('[')
        
        for section in sections[1:]:
            try:
                lines = section.strip().split('\n')
                news_idx = int(lines[0].split(']')[0]) - 1
                
                if news_idx >= len(news_batch):
                    continue
                
                news = news_batch[news_idx]
                event_type = ""
                opportunity_score = 0
                
                for line in lines[1:]:
                    line_lower = line.lower()
                    
                    # Event Type íŒŒì‹±
                    if 'eventtype:' in line_lower:
                        if 'opportunity' in line_lower:
                            event_type = 'opportunity'
                        else:
                            event_type = 'risk'
                    
                    # Risk Score íŒŒì‹±
                    elif 'riskscore:' in line_lower:
                        score_match = re.findall(r'\d+', line)
                        if score_match:
                            news.risk_score = float(score_match[0])
                    
                    # Opportunity Score íŒŒì‹±
                    elif 'opportunityscore:' in line_lower:
                        score_match = re.findall(r'\d+', line)
                        if score_match:
                            opportunity_score = float(score_match[0])
                    
                    # Category íŒŒì‹±
                    elif 'riskcategory:' in line_lower:
                        parts = line.split(':', 1)
                        if len(parts) > 1:
                            news.risk_category = parts[1].strip()
                
                # ë¦¬ìŠ¤í¬ ë ˆë²¨ ì„¤ì • (ì¡°ì •ëœ ì„ê³„ê°’)
                if event_type == 'opportunity' and opportunity_score > 0:
                    news.risk_score = opportunity_score
                    
                    # ê¸°íšŒ ë ˆë²¨ ì„¤ì •
                    if opportunity_score >= 80:  # HIGH
                        news.risk_level = 'HIGH'
                        news.risk_category = f"OPPORTUNITY: {news.risk_category}"
                    elif opportunity_score >= 60:  # MEDIUM
                        news.risk_level = 'MEDIUM'
                        news.risk_category = f"OPPORTUNITY: {news.risk_category}"
                    elif opportunity_score >= 40:  # LOW
                        news.risk_level = 'LOW'
                        news.risk_category = f"OPPORTUNITY: {news.risk_category}"
                    else:
                        news.risk_level = 'VERY_LOW'
                else:
                    # ë¦¬ìŠ¤í¬ ë ˆë²¨ ì„¤ì •
                    if news.risk_score >= self.risk_thresholds['HIGH']:  # 80
                        news.risk_level = 'HIGH'
                        news.risk_category = f"RISK: {news.risk_category}"
                    elif news.risk_score >= self.risk_thresholds['MEDIUM']:  # 60
                        news.risk_level = 'MEDIUM'
                        news.risk_category = f"RISK: {news.risk_category}"
                    elif news.risk_score >= self.risk_thresholds['LOW']:  # 40
                        news.risk_level = 'LOW'
                        news.risk_category = f"RISK: {news.risk_category}"
                    else:
                        news.risk_level = 'VERY_LOW'
                
                news.ai_analysis_timestamp = datetime.now().isoformat()
                results.append(news)
                
            except Exception as e:
                logger.error(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
        
        return results
    
    def summarize_and_translate(self, news_list: List[NewsItem]) -> List[NewsItem]:
        """ë‰´ìŠ¤ ìš”ì•½ ë° í•œêµ­ì–´ ë²ˆì—­"""
        logger.info("ğŸ“ ë‰´ìŠ¤ ìš”ì•½ ë° ë²ˆì—­ ì‹œì‘...")
        
        # ë¦¬ìŠ¤í¬ ë ˆë²¨ì´ ìˆëŠ” ë‰´ìŠ¤ë§Œ ì¹´ìš´íŠ¸ (COMPANY í¬í•¨)
        total_items = len([n for n in news_list if n.risk_level in ['HIGH', 'MEDIUM', 'LOW', 'COMPANY']])
        processed = 0
        
        for news in news_list:
            if not news.risk_level:
                continue
            
            try:
                # HIGHëŠ” ì „ì²´ ë²ˆì—­, ë‚˜ë¨¸ì§€ëŠ” ìš”ì•½ë§Œ
                if news.risk_level == 'HIGH':
                    prompt = f"""Please translate the title and content, then summarize the following news into Korean.

    Title: {news.title}
    Content: {news.snippet}
    Date: {news.date}
    Country: {news.country}

    Please respond in the following format:
    [Title Translation]
    (Korean translation of the title)

    [Summary]
    (3-4 sentences summarizing key points in Korean)

    [Full Translation]
    (Complete translation of the content in natural Korean)"""
                    
                else:  # MEDIUM, LOW, COMPANY
                    prompt = f"""Please translate the title and summarize the following news in 3-4 sentences in Korean.

    Title: {news.title}
    Content: {news.snippet}
    Date: {news.date}
    Country: {news.country}

    Please respond in the following format:
    [Title Translation]
    (Korean translation of the title)

    [Summary]
    (3-4 sentences summarizing key points in Korean)"""
                
                response = self.model.generate_content(prompt)
                result = response.text
                
                # ê²°ê³¼ íŒŒì‹±
                if '[Title Translation]' in result:
                    if news.risk_level == 'HIGH':
                        parts = result.split('[Title Translation]')[1]
                        if '[Summary]' in parts:
                            title_ko = parts.split('[Summary]')[0].strip()
                            remaining = parts.split('[Summary]')[1]
                            if '[Full Translation]' in remaining:
                                summary = remaining.split('[Full Translation]')[0].strip()
                                translation = remaining.split('[Full Translation]')[1].strip()
                            else:
                                summary = remaining.strip()
                                translation = ""
                        else:
                            title_ko = parts.strip()
                            summary = ""
                            translation = ""
                        
                        news.ai_title_ko = title_ko
                        news.ai_summary_ko = summary
                        news.ai_full_translation_ko = translation
                        
                    else:  # MEDIUM, LOW, COMPANY
                        if '[Summary]' in result:
                            title_ko = result.split('[Title Translation]')[1].split('[Summary]')[0].strip()
                            summary = result.split('[Summary]')[1].strip()
                            news.ai_title_ko = title_ko
                            news.ai_summary_ko = summary
                        else:
                            news.ai_title_ko = news.title
                            news.ai_summary_ko = result.strip()
                
                time.sleep(0.5)
                processed += 1
                
                if processed % 10 == 0:
                    logger.info(f"  - ë²ˆì—­ ì§„í–‰: {processed}/{total_items}")
                    
            except Exception as e:
                logger.error(f"ë²ˆì—­/ìš”ì•½ ì˜¤ë¥˜ ({news.title[:50]}...): {e}")
                news.ai_title_ko = news.title
                news.ai_summary_ko = "ë²ˆì—­ ì‹¤íŒ¨"
        
        logger.info(f"âœ… ìš”ì•½ ë° ë²ˆì—­ ì™„ë£Œ: {processed}ê±´ ì²˜ë¦¬")
        return news_list

    def remove_company_duplicates(self, new_news: List[NewsItem], 
                                 existing_news: List[NewsItem]) -> List[NewsItem]:
        """íšŒì‚¬ ë‰´ìŠ¤ ì „ìš© ì¤‘ë³µ ì œê±° - ê¸°ì¡´ ë‰´ìŠ¤ì™€ ë¹„êµ"""
        
        logger.info("ğŸ” íšŒì‚¬ ë‰´ìŠ¤ AI ê¸°ë°˜ ì¤‘ë³µ ì œê±° ì‹œì‘...")
        
        if not new_news:
            return []
        
        if not existing_news:
            # ê¸°ì¡´ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ëª¨ë‘ ìƒˆë¡œìš´ ë‰´ìŠ¤
            return new_news
        
        unique_news = []
        duplicate_count = 0
        
        for candidate in new_news:
            is_duplicate = False
            duplicate_of = None
            
            # ê¸°ì¡´ ë‰´ìŠ¤ì™€ ë¹„êµ (ìµœëŒ€ 20ê°œì™€ ë¹„êµ)
            comparison_news = existing_news[-20:] if len(existing_news) > 20 else existing_news
            
            if comparison_news:
                is_duplicate, duplicate_of = self._check_duplicate_with_ai(
                    candidate, 
                    comparison_news
                )
            
            if not is_duplicate:
                unique_news.append(candidate)
                logger.debug(f"  âœ“ ìƒˆë¡œìš´ ë‰´ìŠ¤: {candidate.title[:50]}...")
            else:
                duplicate_count += 1
                candidate.is_duplicate = True
                candidate.duplicate_of = duplicate_of or ""
                logger.debug(f"  âœ— ì¤‘ë³µ ì œê±°: {candidate.title[:50]}...")
        
        logger.info(f"âœ… íšŒì‚¬ ë‰´ìŠ¤ ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(new_news)}ê±´ â†’ {len(unique_news)}ê±´ (ì¤‘ë³µ {duplicate_count}ê±´)")
        return unique_news

class AIRiskMonitoringSystem:
    """AI ê¸°ë°˜ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config_path='monitoring_config.json'):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("="*70)
        logger.info("ğŸ¤– AI ê¸°ë°˜ ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        logger.info("="*70)
        
        self.serpapi_key = os.getenv('SERPAPI_KEY')
        self.gemini_key = os.getenv('GEMINI_API_KEY')
        
        if not self.serpapi_key:
            logger.error("âŒ SERPAPI_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        if not self.gemini_key:
            logger.error("âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        try:
            from serpapi import GoogleSearch
            self.GoogleSearch = GoogleSearch
            logger.info("âœ… SerpAPI íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ")
        except ImportError:
            logger.error("âŒ serpapi íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        self.analyzer = GeminiAnalyzer(self.gemini_key)
        self.load_config(config_path)
        self.setup_email_config()
        
        # ìˆ˜ì •ëœ í†µê³„ ì •ë³´ - ì™„ì „í•œ í†µê³„
        self.stats = {
            'api_calls': 0,
            'news_collected': 0,
            'news_after_dedup': 0,
            'news_analyzed': 0,
            'high_risk': 0,
            'medium_risk': 0,
            'low_risk': 0,  # ì¶”ê°€
            'company_news': 0,  # ì¶”ê°€
            'total_filtered': 0,  # ì¶”ê°€
            'errors': 0,
            'start_time': datetime.now(),
            'country_breakdown': {}  # ì¶”ê°€ - êµ­ê°€ë³„ í†µê³„
        }

    def update_risk_statistics(self, news_list: List[NewsItem]):
        """ë¦¬ìŠ¤í¬ í†µê³„ ì—…ë°ì´íŠ¸ - ìƒˆë¡œìš´ ë©”ì„œë“œ"""
        self.stats['high_risk'] = 0
        self.stats['medium_risk'] = 0
        self.stats['low_risk'] = 0
        self.stats['company_news'] = 0
        self.stats['country_breakdown'] = {}
        
        for news in news_list:
            # ë¦¬ìŠ¤í¬ ë ˆë²¨ë³„ ì¹´ìš´íŠ¸
            if news.risk_level == 'HIGH':
                self.stats['high_risk'] += 1
            elif news.risk_level == 'MEDIUM':
                self.stats['medium_risk'] += 1
            elif news.risk_level == 'LOW':
                self.stats['low_risk'] += 1
            elif news.risk_level == 'COMPANY':
                self.stats['company_news'] += 1
            
            # êµ­ê°€ë³„ í†µê³„
            country = news.country_ko or news.country
            if country not in self.stats['country_breakdown']:
                self.stats['country_breakdown'][country] = {
                    'total': 0, 'high': 0, 'medium': 0, 'low': 0, 'company': 0
                }
            
            self.stats['country_breakdown'][country]['total'] += 1
            if news.risk_level == 'HIGH':
                self.stats['country_breakdown'][country]['high'] += 1
            elif news.risk_level == 'MEDIUM':
                self.stats['country_breakdown'][country]['medium'] += 1
            elif news.risk_level == 'LOW':
                self.stats['country_breakdown'][country]['low'] += 1
            elif news.risk_level == 'COMPANY':
                self.stats['country_breakdown'][country]['company'] += 1
        
        self.stats['total_filtered'] = len(news_list)
 
    def load_config(self, config_path):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            
            self.countries = {
                k: v for k, v in self.config['countries'].items() 
                if v.get('active', True)
            }
            
            self.risk_keywords = self.config['search_keywords']['risk_keywords']
            self.combined_query = self.config['search_keywords']['combined_query']
            self.company_keywords = self.config['company_keywords']
            self.korean_media = self.config.get('korean_media', {})
            
            logger.info(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
            
        except Exception as e:
            logger.error(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            sys.exit(1)
    
    def setup_email_config(self):
        """ì´ë©”ì¼ ì„¤ì •"""
        self.email_config = {
            'smtp_server': os.getenv('SMTP_SERVER', 'smtp.gmail.com'),
            'smtp_port': int(os.getenv('SMTP_PORT', 587)),
            'sender_email': os.getenv('SENDER_EMAIL', ''),
            'sender_password': os.getenv('SENDER_PASSWORD', ''),
            'recipients': [],
            'admin_email': os.getenv('ADMIN_EMAIL', '')  # ê´€ë¦¬ì ì´ë©”ì¼ ì¶”ê°€
        }
        
        env_recipients = os.getenv('RECIPIENT_EMAILS', '')
        if env_recipients:
            self.email_config['recipients'] = [
                email.strip() for email in env_recipients.split(',')
            ]

    def search_news(self, query: str, country_code: str = None, 
                country_name: str = None, search_type: str = 'news') -> List[NewsItem]:
        """ë‰´ìŠ¤ ê²€ìƒ‰ - 7ì¼ ì´ë‚´ ë‰´ìŠ¤ë§Œ"""
        results = []
        
        # í˜„ì¬ ì‹œê°„ê³¼ 7ì¼ ì „ ì‹œê°„ ì„¤ì •
        now = datetime.now()
        seven_days_ago = now - timedelta(days=7)
        
        logger.debug(f"ë‚ ì§œ í•„í„°: {seven_days_ago.strftime('%Y-%m-%d')} ~ {now.strftime('%Y-%m-%d')}")
        
        try:
            if search_type == 'news':
                params = {
                    "api_key": self.serpapi_key,
                    "engine": "google_news",
                    "q": query,
                    "when": "7d"  # ìµœê·¼ 7ì¼
                }
                
                if country_code:
                    params["gl"] = country_code
                    params["hl"] = "en"
            else:
                params = {
                    "api_key": self.serpapi_key,
                    "engine": "google",
                    "q": query,
                    "num": "10",
                    "tbs": "qdr:w"  # ìµœê·¼ 1ì£¼ì¼
                }
                
                if country_code:
                    params["gl"] = country_code
                    params["hl"] = "ko" if country_code == "kr" else "en"
            
            search = self.GoogleSearch(params)
            response = search.get_dict()
            
            self.stats['api_calls'] += 1
            
            # ê²°ê³¼ íŒŒì‹±
            if search_type == 'news' and "news_results" in response:
                for item in response["news_results"][:20]:
                    date_str = item.get('date', '')
                    
                    # í†µì¼ëœ ë‚ ì§œ ê²€ì¦ í•¨ìˆ˜ ì‚¬ìš© (ìˆ˜ì •ëœ ë¶€ë¶„)
                    if not self._is_within_days(date_str, 7):
                        logger.debug(f"  âœ— 7ì¼ ì´ì „ ë‰´ìŠ¤ ì œì™¸: {item.get('title', '')[:50]}... ({date_str})")
                        continue
                    
                    logger.debug(f"  âœ” í¬í•¨: {item.get('title', '')[:30]}... ({date_str})")
                    
                    news_item = NewsItem(
                        title=item.get('title', ''),
                        date=date_str,
                        source=item.get('source', {}).get('name', 'Unknown'),
                        snippet=item.get('snippet', ''),
                        link=item.get('link', ''),
                        country=country_name or 'Global',
                        country_code=country_code or 'global',
                        thumbnail=item.get('thumbnail', ''),
                        search_type=search_type,
                        collected_at=now.isoformat()
                    )
                    results.append(news_item)
                    
            elif search_type != 'news' and "organic_results" in response:
                # Google SearchëŠ” ì´ë¯¸ ìµœì‹  ê²°ê³¼ë§Œ ë°˜í™˜
                for item in response["organic_results"][:20]:
                    news_item = NewsItem(
                        title=item.get('title', ''),
                        date=now.strftime('%Y-%m-%d'),
                        source=item.get('displayed_link', 'Unknown'),
                        snippet=item.get('snippet', ''),
                        link=item.get('link', ''),
                        country=country_name or 'Korea',
                        country_code=country_code or 'kr',
                        search_type=search_type,
                        collected_at=now.isoformat()
                    )
                    results.append(news_item)
            
            self.stats['news_collected'] += len(results)
            
            if results:
                logger.info(f"  âœ” {len(results)}ê±´ ìˆ˜ì§‘ (7ì¼ ì´ë‚´)")
            else:
                logger.info(f"  âœ— 7ì¼ ì´ë‚´ ë‰´ìŠ¤ ì—†ìŒ")
            
        except Exception as e:
            logger.error(f"API ì˜¤ë¥˜: {e}")
            self.stats['errors'] += 1
        
        return results
    
    def collect_all_news(self) -> List[NewsItem]:
        """ëª¨ë“  ë‰´ìŠ¤ ìˆ˜ì§‘"""
        all_news = []
        
        # 1. êµ­ê°€ë³„ ë¦¬ìŠ¤í¬ ë‰´ìŠ¤ ìˆ˜ì§‘
        logger.info("\nğŸŒ êµ­ê°€ë³„ ë¦¬ìŠ¤í¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
        for idx, (country_code, country_info) in enumerate(self.countries.items(), 1):
            logger.info(f"[{idx}/{len(self.countries)}] {country_info['name_ko']} ({country_info['name']})")
            
            query = f'("{country_info["name"]}" disaster OR "{country_info["name"]}" accident OR "{country_info["name"]}" crisis OR "{country_info["name"]}" emergency)'
            
            news = self.search_news(
                query=query,
                country_code=country_info['gl'],
                country_name=country_info['name'],
                search_type='news'
            )
            
            for item in news:
                item.country_ko = country_info['name_ko']
            
            logger.info(f"  - {country_info['name']}: {len(news)}ê±´ ìˆ˜ì§‘")
            all_news.extend(news)
            time.sleep(1)
        
        # 2. íšŒì‚¬ í‚¤ì›Œë“œ ë‰´ìŠ¤ ìˆ˜ì§‘ (í•´ì™¸ë§Œ) - ìˆ˜ì •ë¨
        logger.info("\nğŸ¢ íšŒì‚¬ í‚¤ì›Œë“œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (í•´ì™¸ë§Œ)")
        
        # ì œì™¸í•  í•œêµ­ ì–¸ë¡ ì‚¬
        korean_sources = ['yonhap', 'ì—°í•©', 'korea', 'chosun', 'ì¡°ì„ ', 
                        'joongang', 'ì¤‘ì•™', 'hankyoreh', 'í•œê²¨ë ˆ', 'donga', 'ë™ì•„',
                        'hankook', 'í•œêµ­', 'maeil', 'ë§¤ì¼', 'seoul', 'ì„œìš¸']
        
        # ì œì™¸í•  íšŒì‚¬ ê³µì‹ ì±„ë„
        official_sources = ['samsung newsroom', 'ì‚¼ì„± ë‰´ìŠ¤ë£¸', 'samsung.com', 
                        'samsungcnt.com', 'samsung c&t newsroom']
        
        # ê±´ì„¤ì—… ê´€ë ¨ í‚¤ì›Œë“œ (í•„í„°ë§ìš©)
        construction_keywords = ['construction', 'building', 'infrastructure', 'engineering',
                                'project', 'development', 'contractor', 'architecture',
                                'ê±´ì„¤', 'ê±´ì¶•', 'ê³µì‚¬', 'ì‹œê³µ', 'í”„ë¡œì íŠ¸', 'ê°œë°œ']
        
        for idx, keyword in enumerate(self.company_keywords, 1):
            logger.info(f"[{idx}/{len(self.company_keywords)}] {keyword}")
            
            # ê±´ì„¤ì—… ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨í•œ ê²€ìƒ‰ì–´
            query = f'"{keyword}" (construction OR building OR project OR infrastructure) -site:kr -korea -í•œêµ­ -newsroom'
            
            try:
                params = {
                    "api_key": self.serpapi_key,
                    "engine": "google_news",
                    "q": query,
                    "when": "7d",
                    "gl": "us",
                    "hl": "en"
                }
                
                search = self.GoogleSearch(params)
                response = search.get_dict()
                
                self.stats['api_calls'] += 1
                
                if "news_results" in response:
                    company_news = []
                    
                    for item in response["news_results"][:30]:  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§
                        # ë‚ ì§œ í•„í„°ë§
                        date_str = item.get('date', '')
                        if not self._is_within_days(date_str, 7):
                            continue
                        
                        # ì†ŒìŠ¤ í•„í„°ë§
                        source = item.get('source', {}).get('name', '').lower()
                        
                        # í•œêµ­ ì–¸ë¡ ì‚¬ ì œì™¸
                        if any(ks in source for ks in korean_sources):
                            logger.debug(f"  âœ— í•œêµ­ ì–¸ë¡ ì‚¬ ì œì™¸: {source}")
                            continue
                        
                        # íšŒì‚¬ ê³µì‹ ì±„ë„ ì œì™¸
                        if any(os in source for os in official_sources):
                            logger.debug(f"  âœ— íšŒì‚¬ ê³µì‹ ì±„ë„ ì œì™¸: {source}")
                            continue
                        
                        # ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ê±´ì„¤ì—… ê´€ë ¨ì„± ì²´í¬
                        title = item.get('title', '').lower()
                        snippet = item.get('snippet', '').lower()
                        
                        # ê±´ì„¤ì—… ê´€ë ¨ í‚¤ì›Œë“œê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì œì™¸
                        has_construction_relevance = any(
                            ck.lower() in title or ck.lower() in snippet 
                            for ck in construction_keywords
                        )
                        
                        if not has_construction_relevance:
                            logger.debug(f"  âœ— ê±´ì„¤ì—… ë¬´ê´€: {item.get('title', '')[:50]}...")
                            continue
                        
                        news_item = NewsItem(
                            title=item.get('title', ''),
                            date=date_str,
                            source=item.get('source', {}).get('name', 'Unknown'),
                            snippet=item.get('snippet', ''),
                            link=item.get('link', ''),
                            country="Global",
                            country_ko="í•´ì™¸",
                            country_code="global_samsung",
                            thumbnail=item.get('thumbnail', ''),
                            search_type='company_global',
                            collected_at=datetime.now().isoformat()
                        )
                        company_news.append(news_item)
                        
                        # ìµœëŒ€ 10ê±´ë§Œ ìˆ˜ì§‘
                        if len(company_news) >= 10:
                            break
                    
                    logger.info(f"  - {keyword}: {len(company_news)}ê±´ ìˆ˜ì§‘ (ê±´ì„¤ì—… ê´€ë ¨, ê³µì‹ì±„ë„ ì œì™¸)")
                    all_news.extend(company_news)
                    self.stats['news_collected'] += len(company_news)
                    
            except Exception as e:
                logger.error(f"íšŒì‚¬ í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜ ({keyword}): {e}")
                self.stats['errors'] += 1
            
            time.sleep(1)
        
        # 3. í•œêµ­ ë¯¸ë””ì–´ ê²€ìƒ‰ ì¶”ê°€ (ê¸°ì¡´ ìœ ì§€)
        logger.info("\nğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  ë‚´ íšŒì‚¬ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§")
        for site in self.korean_media.get('sites', []):
            if not site.get('active', False):
                continue
            
            for term in self.korean_media.get('search_terms', []):
                query = f'{site["selector"]} "{term}"'
                logger.info(f"  - {site['name']}: {term}")
                news = self.search_news(
                    query=query,
                    country_code='kr',
                    country_name='Korea',
                    search_type='web'
                )
                
                for item in news:
                    item.country = "Samsung C&T"
                    item.country_ko = "ì‚¼ì„±ë¬¼ì‚°"
                    item.country_code = "samsung"
                
                all_news.extend(news)
                time.sleep(1)
        
        logger.info(f"\nâœ… ì´ {len(all_news)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_news
    
    def _is_within_days(self, date_string: str, days: int = 7) -> bool:
        """í†µì¼ëœ ë‚ ì§œ ê²€ì¦ í•¨ìˆ˜ - ì§€ì •ëœ ì¼ìˆ˜ ì´ë‚´ì¸ì§€ í™•ì¸"""
        try:
            target_date = datetime.now() - timedelta(days=days)
            date_lower = date_string.lower()
            
            # ìƒëŒ€ì  ì‹œê°„ ì²˜ë¦¬
            relative_terms = ['today', 'yesterday', 'hour ago', 'hours ago', 
                            'minute ago', 'minutes ago', 'just now']
            if any(term in date_lower for term in relative_terms):
                return True
            
            # X days ago íŒ¨í„´
            if 'day ago' in date_lower or 'days ago' in date_lower:
                days_match = re.search(r'(\d+)\s*days?\s*ago', date_lower)
                if days_match:
                    days_num = int(days_match.group(1))
                    return days_num <= days
            
            # ì ˆëŒ€ ë‚ ì§œ íŒŒì‹± - ë‹¤ì–‘í•œ í˜•ì‹ ì‹œë„
            date_formats = ['%m/%d/%Y', '%Y-%m-%d', '%d %B %Y', '%B %d, %Y', 
                        '%d/%m/%Y', '%Y/%m/%d']
            
            for fmt in date_formats:
                try:
                    parsed_date = datetime.strptime(date_string.split(',')[0].strip(), fmt)
                    return parsed_date >= target_date
                except:
                    continue
            
            # dateutil parser ì‚¬ìš© (ìµœí›„ì˜ ìˆ˜ë‹¨)
            try:
                parsed_date = parser.parse(date_string, fuzzy=True)
                # ë¯¸ë˜ ë‚ ì§œë©´ ì‘ë…„ìœ¼ë¡œ ì¡°ì •
                if parsed_date > datetime.now():
                    parsed_date = parsed_date.replace(year=parsed_date.year - 1)
                return parsed_date >= target_date
            except:
                pass
            
            # ì›” ì´ë¦„ íŒ¨í„´ íŠ¹ë³„ ì²˜ë¦¬
            months_pattern = r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\s+(\d{1,2})'
            month_match = re.search(months_pattern, date_string)
            if month_match:
                month_str, day = month_match.groups()
                current_year = datetime.now().year
                try:
                    test_date = parser.parse(f"{month_str} {day}, {current_year}")
                    if test_date > datetime.now():
                        test_date = parser.parse(f"{month_str} {day}, {current_year - 1}")
                    return test_date >= target_date
                except:
                    pass
            
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì œì™¸ (ì•ˆì „í•œ ì„ íƒ)
            logger.debug(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_string}")
            return False
            
        except Exception as e:
            logger.debug(f"ë‚ ì§œ ê²€ì¦ ì˜¤ë¥˜: {date_string} - {e}")
            return False
    
    def create_ai_html_report(self, analyzed_news: List[NewsItem]) -> str:
        """AI ë¶„ì„ ê²°ê³¼ë¥¼ í¬í•¨í•œ HTML ë¦¬í¬íŠ¸ ìƒì„± - ì‚¼ì„±ë¬¼ì‚° ìµœìƒë‹¨ í‘œì‹œ"""
        
        # ë¶„ë¥˜ (COMPANY ì œê±°, OPPORTUNITY ì¶”ê°€)
        high_risk = [n for n in analyzed_news if n.risk_level == 'HIGH' and 'RISK:' in n.risk_category]
        high_opportunities = [n for n in analyzed_news if n.risk_level == 'HIGH' and 'OPPORTUNITY:' in n.risk_category]
        medium_risk = [n for n in analyzed_news if n.risk_level == 'MEDIUM']
        low_risk = [n for n in analyzed_news if n.risk_level == 'LOW']
        
        # êµ­ê°€ë³„ í†µê³„ ê³„ì‚°
        country_stats = {}
        for news in analyzed_news:
            country = news.country_ko or news.country
            if country not in country_stats:
                country_stats[country] = {'HIGH_RISK': 0, 'HIGH_OPP': 0, 'MEDIUM': 0, 'LOW': 0, 'total': 0}
            
            if news.risk_level == 'HIGH':
                if 'OPPORTUNITY:' in news.risk_category:
                    country_stats[country]['HIGH_OPP'] += 1
                else:
                    country_stats[country]['HIGH_RISK'] += 1
            elif news.risk_level == 'MEDIUM':
                country_stats[country]['MEDIUM'] += 1
            elif news.risk_level == 'LOW':
                country_stats[country]['LOW'] += 1
            
            country_stats[country]['total'] += 1
        
        # ì¸ë¼ì¸ ìŠ¤íƒ€ì¼ë¡œ í†µì¼ëœ HTML
        html = f"""<!DOCTYPE html>
        <html lang="ko">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ - {datetime.now().strftime('%Y-%m-%d')}</title>
        </head>
        <body style="margin: 0; padding: 0; font-family: 'Malgun Gothic', Arial, sans-serif; background-color: #f4f4f4;">
            <div style="max-width: 800px; margin: 0 auto; background-color: #ffffff;">
                
                <!-- í—¤ë” -->
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 40px; text-align: center;">
                    <h1 style="color: #ffffff; margin: 0 0 10px 0; font-size: 32px;">ğŸŒ G/Oì‹¤ ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸</h1>
                    <div style="display: inline-block; background: rgba(255,255,255,0.2); padding: 5px 15px; border-radius: 20px; color: white; font-size: 14px;">
                        Powered by Gemini 2.0 Flash
                    </div>
                </div>
                
                <!-- í†µê³„ ì¹´ë“œ -->
                <div style="background: #f8f9fa; padding: 30px; border-bottom: 2px solid #e9ecef;">
                    <table style="width: 100%; border-collapse: collapse;">
                        <tr>
                            <td style="text-align: center; padding: 15px;">
                                <div style="font-size: 36px; font-weight: bold;">{len(analyzed_news)}</div>
                                <div style="color: #666; margin-top: 5px; font-size: 12px;">Total News</div>
                            </td>
                            <td style="text-align: center; padding: 15px;">
                                <div style="font-size: 36px; font-weight: bold; color: #dc3545;">{len(high_risk)}</div>
                                <div style="color: #666; margin-top: 5px; font-size: 12px;">High Risk</div>
                            </td>
                            <td style="text-align: center; padding: 15px;">
                                <div style="font-size: 36px; font-weight: bold; color: #28a745;">{len(high_opportunities)}</div>
                                <div style="color: #666; margin-top: 5px; font-size: 12px;">High Opportunity</div>
                            </td>
                            <td style="text-align: center; padding: 15px;">
                                <div style="font-size: 36px; font-weight: bold; color: #ffc107;">{len(medium_risk)}</div>
                                <div style="color: #666; margin-top: 5px; font-size: 12px;">Medium Risk</div>
                            </td>
                            <td style="text-align: center; padding: 15px;">
                                <div style="font-size: 36px; font-weight: bold; color: #6c757d;">{len(low_risk)}</div>
                                <div style="color: #666; margin-top: 5px; font-size: 12px;">Low Risk</div>
                            </td>
                        </tr>
                    </table>
                </div>
                
                <!-- êµ­ê°€ë³„ ë¦¬ìŠ¤í¬ í˜„í™© -->
                <div style="padding: 30px; background-color: #f8f9fa;">
                    <h2 style="margin: 0 0 20px 0; color: #333;">ğŸ“Š êµ­ê°€ë³„ ë¦¬ìŠ¤í¬ í˜„í™©</h2>
                    <table style="width: 100%; border-collapse: collapse; background: white; box-shadow: 0 2px 5px rgba(0,0,0,0.1);">
                        <thead>
                            <tr style="background-color: #6c757d; color: white;">
                                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">êµ­ê°€</th>
                                <th style="padding: 12px; text-align: center; border: 1px solid #dee2e6;">HIGH RISK</th>
                                <th style="padding: 12px; text-align: center; border: 1px solid #dee2e6;">HIGH OPP</th>
                                <th style="padding: 12px; text-align: center; border: 1px solid #dee2e6;">MEDIUM</th>
                                <th style="padding: 12px; text-align: center; border: 1px solid #dee2e6;">LOW</th>
                                <th style="padding: 12px; text-align: center; border: 1px solid #dee2e6;">ì†Œê³„</th>
                            </tr>
                        </thead>
                        <tbody>"""
        
        # ì‚¼ì„±ë¬¼ì‚° ê´€ë ¨ ë‰´ìŠ¤ ë¨¼ì € í‘œì‹œ
        samsung_keys = ['ì‚¼ì„±ë¬¼ì‚°', 'Samsung C&T', 'í•´ì™¸']  # íšŒì‚¬ ê´€ë ¨ í‚¤ì›Œë“œë“¤
        samsung_stats_displayed = False
        
        for key in samsung_keys:
            if key in country_stats:
                stats = country_stats[key]
                # ì‚¼ì„±ë¬¼ì‚° í–‰ì€ ë°°ê²½ìƒ‰ì„ ë‹¤ë¥´ê²Œ í•˜ì—¬ ê°•ì¡°
                html += f"""
                            <tr style="background-color: #e3f2fd;">
                                <td style="padding: 10px; border: 1px solid #dee2e6; font-weight: bold;">
                                    ğŸ¢ {key}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #dc3545; color: white; padding: 2px 8px; border-radius: 4px;">{stats["HIGH_RISK"]}</span>' if stats['HIGH_RISK'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #28a745; color: white; padding: 2px 8px; border-radius: 4px;">{stats["HIGH_OPP"]}</span>' if stats['HIGH_OPP'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #ffc107; color: black; padding: 2px 8px; border-radius: 4px;">{stats["MEDIUM"]}</span>' if stats['MEDIUM'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #6c757d; color: white; padding: 2px 8px; border-radius: 4px;">{stats["LOW"]}</span>' if stats['LOW'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;">
                                    {stats['total']}
                                </td>
                            </tr>"""
                samsung_stats_displayed = True
                break  # í•˜ë‚˜ë§Œ í‘œì‹œ
        
        # êµ¬ë¶„ì„  ì¶”ê°€ (ì‚¼ì„±ë¬¼ì‚°ê³¼ ë‹¤ë¥¸ êµ­ê°€ êµ¬ë¶„)
        if samsung_stats_displayed and len(country_stats) > 1:
            html += """
                            <tr>
                                <td colspan="6" style="padding: 0; border: none; background-color: #dee2e6; height: 2px;"></td>
                            </tr>"""
        
        # ë‚˜ë¨¸ì§€ êµ­ê°€ë“¤ì„ total ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ
        other_countries = sorted(
            [(k, v) for k, v in country_stats.items() if k not in samsung_keys],
            key=lambda x: x[1]['total'],
            reverse=True
        )
        
        for country, stats in other_countries:
            html += f"""
                            <tr>
                                <td style="padding: 10px; border: 1px solid #dee2e6;">{country}</td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #dc3545; color: white; padding: 2px 8px; border-radius: 4px;">{stats["HIGH_RISK"]}</span>' if stats['HIGH_RISK'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #28a745; color: white; padding: 2px 8px; border-radius: 4px;">{stats["HIGH_OPP"]}</span>' if stats['HIGH_OPP'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #ffc107; color: black; padding: 2px 8px; border-radius: 4px;">{stats["MEDIUM"]}</span>' if stats['MEDIUM'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6;">
                                    {f'<span style="background: #6c757d; color: white; padding: 2px 8px; border-radius: 4px;">{stats["LOW"]}</span>' if stats['LOW'] > 0 else '-'}
                                </td>
                                <td style="padding: 10px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;">{stats['total']}</td>
                            </tr>"""
        
        html += """
                        </tbody>
                    </table>
                </div>
                
                <!-- ë‰´ìŠ¤ ë‚´ìš© -->
                <div style="padding: 40px;">
        """
        
        # HIGH OPPORTUNITY ì„¹ì…˜ (ìµœìƒë‹¨)
        if high_opportunities:
            html += """
                    <h2 style="color: #28a745; margin: 30px 0 20px 0;">ğŸ’ HIGH OPPORTUNITY - ì£¼ìš” ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ</h2>"""
            for news in high_opportunities:
                html += self._create_ai_news_card(news, 'opportunity')
        
        # HIGH RISK ì„¹ì…˜
        if high_risk:
            html += """
                    <h2 style="color: #dc3545; margin: 30px 0 20px 0;">âš ï¸ HIGH RISK - ì¦‰ì‹œ í™•ì¸ í•„ìš”</h2>"""
            for news in high_risk:
                html += self._create_ai_news_card(news, 'high')
        
        # MEDIUM RISK ì„¹ì…˜
        if medium_risk:
            html += """
                    <h2 style="color: #ffc107; margin: 30px 0 20px 0;">ğŸ”” MEDIUM RISK - ì£¼ì˜ í•„ìš”</h2>"""
            for news in medium_risk:
                html += self._create_ai_news_card(news, 'medium')
        
        # LOW RISK ì„¹ì…˜
        if low_risk:
            html += """
                    <h2 style="color: #6c757d; margin: 30px 0 20px 0;">â„¹ï¸ LOW RISK - ëª¨ë‹ˆí„°ë§</h2>"""
            for news in low_risk:
                html += self._create_ai_news_card(news, 'low')
        
        html += """
                </div>
                
                <!-- í‘¸í„° -->
                <div style="background-color: #f8f9fa; padding: 20px; text-align: center; border-top: 1px solid #dee2e6;">
                    <p style="margin: 0; color: #666; font-size: 12px;">
                        Samsung C&T Risk Monitoring System<br>
                        Generated at """ + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + """
                    </p>
                </div>
            </div>
        </body>
        </html>"""
        
        return html
    
    def _create_ai_news_card(self, news: NewsItem, risk_class: str) -> str:
        """ë‰´ìŠ¤ ì¹´ë“œ HTML ìƒì„± - opportunity í´ë˜ìŠ¤ ì¶”ê°€"""
        import html
        
        # í•œêµ­ì–´ ì œëª© ìš°ì„  ì‚¬ìš©
        title_to_display = news.ai_title_ko if news.ai_title_ko else news.title
        
        # ë¦¬ìŠ¤í¬ ë ˆë²¨ì— ë”°ë¥¸ ìƒ‰ìƒ
        color_map = {
            'high': '#dc3545',
            'medium': '#ffc107', 
            'low': '#6c757d',
            'opportunity': '#28a745'  # ê¸°íšŒ ìƒ‰ìƒ ì¶”ê°€
        }
        border_color = color_map.get(risk_class, '#6c757d')
        
        # ì¹´í…Œê³ ë¦¬ í‘œì‹œ ì •ë¦¬
        category_display = news.risk_category.replace('RISK: ', '').replace('OPPORTUNITY: ', '')
        
        # ê¸°íšŒ/ìœ„í—˜ì— ë”°ë¥¸ ë¼ë²¨
        if risk_class == 'opportunity':
            score_label = "ì¤‘ìš”ë„"
            category_label = "ê¸°íšŒ ìœ í˜•"
        else:
            score_label = "ë¦¬ìŠ¤í¬ ì ìˆ˜"
            category_label = "ì¹´í…Œê³ ë¦¬"
        
        return f"""
            <div style="background: white; border: 1px solid #e9ecef; border-left: 5px solid {border_color}; border-radius: 8px; padding: 20px; margin-bottom: 20px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
                <h3 style="margin: 0 0 10px 0; color: #333; font-size: 18px;">{html.escape(title_to_display)}</h3>
                <p style="margin: 10px 0; color: #666; font-size: 13px;">
                    ğŸ“ {news.country_ko or news.country} | ğŸ“° {html.escape(news.source)} | ğŸ“… {news.date}
                </p>
                <p style="margin: 10px 0;">
                    <strong>{score_label}:</strong> {news.risk_score:.0f} | 
                    <strong>{category_label}:</strong> {category_display}
                </p>
                <div style="background: #f8f9fa; padding: 10px; border-radius: 4px; margin: 15px 0;">
                    <strong>AI ìš”ì•½:</strong><br>
                    <p style="margin: 5px 0; color: #333; line-height: 1.6;">
                        {html.escape(news.ai_summary_ko or 'No summary')}
                    </p>
                </div>
                <a href="{news.link}" target="_blank" style="display: inline-block; padding: 8px 16px; background: #007bff; color: white; text-decoration: none; border-radius: 4px; font-size: 14px;">
                    ì›ë¬¸ ë³´ê¸° â†’
                </a>
            </div>"""
    
    def send_email_report(self, html_content: str, news_list: List[NewsItem]) -> bool:
        """ì´ë©”ì¼ë¡œ ë¦¬í¬íŠ¸ ì „ì†¡"""
        try:
            high_risk_count = len([n for n in news_list if n.risk_level == 'HIGH'])
            
            subject = f"[ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§] {datetime.now().strftime('%Y-%m-%d')} - "
            if high_risk_count > 0:
                subject += f"âš ï¸ HIGH RISK {high_risk_count}ê±´ ë°œìƒ"
            else:
                subject += "ì •ìƒ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ"
            
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.email_config['sender_email']
            msg['To'] = ', '.join(self.email_config['recipients'])
            
            html_part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(html_part)
            
            with smtplib.SMTP(self.email_config['smtp_server'], self.email_config['smtp_port']) as server:
                server.starttls()
                server.login(self.email_config['sender_email'], self.email_config['sender_password'])
                server.send_message(msg)
                
            logger.info(f"ğŸ“§ ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ: {', '.join(self.email_config['recipients'])}")
            return True
            
        except Exception as e:
            logger.error(f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False

    def run_daily_monitoring(self):
        """ì¼ì¼ ì „ì²´ ëª¨ë‹ˆí„°ë§ (ì˜¤ì „ 7ì‹œ ì‹¤í–‰)"""
        logger.info("\n" + "="*70)
        logger.info("ğŸŒ… ì¼ì¼ ì „ì²´ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        logger.info("="*70)
        
        try:
            # ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘ (êµ­ê°€ë³„ + íšŒì‚¬)
            all_news = self.collect_all_news()
            
            # AI ë¶„ì„ í”„ë¡œì„¸ìŠ¤
            unique_news = self.analyzer.remove_duplicates(all_news)
            self.stats['news_after_dedup'] = len(unique_news)
            
            analyzed_news = self.analyzer.analyze_risk_batch(unique_news)
            self.stats['news_analyzed'] = len(analyzed_news)
            
            final_news = self.analyzer.summarize_and_translate(analyzed_news)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.update_risk_statistics(final_news)
            
            # ë¦¬í¬íŠ¸ ìƒì„± ë° ì´ë©”ì¼ ì „ì†¡
            html_content = self.create_ai_html_report(final_news)
            
            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            html_file = f'daily_risk_report_{timestamp}.html'
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            # ì´ë©”ì¼ ì „ì†¡
            if self.email_config['sender_email'] and self.email_config['recipients']:
                self.send_email_report(html_content, final_news)

            # ìƒì„¸ í†µê³„ ë¡œê·¸ ì¶œë ¥
            self._print_detailed_stats()

            logger.info("âœ… ì¼ì¼ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì¼ì¼ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            return False

    def _print_detailed_stats(self):
        """ìƒì„¸ í†µê³„ ì¶œë ¥ - ìƒˆë¡œìš´ ë©”ì„œë“œ"""
        duration = datetime.now() - self.stats['start_time']
        
        logger.info("\n" + "="*70)
        logger.info("ğŸ“Š ìƒì„¸ í†µê³„ ë³´ê³ ì„œ")
        logger.info("="*70)
        logger.info(f"ì‹¤í–‰ ì‹œê°„: {str(duration).split('.')[0]}")
        logger.info(f"API í˜¸ì¶œ íšŸìˆ˜: {self.stats['api_calls']}")
        logger.info(f"ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {self.stats['news_collected']}ê±´")
        logger.info(f"ì¤‘ë³µ ì œê±° í›„: {self.stats['news_after_dedup']}ê±´")
        logger.info(f"AI ë¶„ì„ ì™„ë£Œ: {self.stats['news_analyzed']}ê±´")
        logger.info(f"ìµœì¢… í•„í„°ë§: {self.stats['total_filtered']}ê±´")
        logger.info("-" * 70)
        logger.info("ë¦¬ìŠ¤í¬ ë ˆë²¨ë³„ ë¶„í¬:")
        logger.info(f"  HIGH: {self.stats['high_risk']}ê±´")
        logger.info(f"  MEDIUM: {self.stats['medium_risk']}ê±´")
        logger.info(f"  LOW: {self.stats['low_risk']}ê±´")
        logger.info(f"  COMPANY: {self.stats['company_news']}ê±´")
        logger.info("-" * 70)
        
        if self.stats['country_breakdown']:
            logger.info("êµ­ê°€ë³„ ë¦¬ìŠ¤í¬ ë¶„í¬ (ìƒìœ„ 5ê°œêµ­):")
            sorted_countries = sorted(
                self.stats['country_breakdown'].items(), 
                key=lambda x: x[1]['total'], 
                reverse=True
            )[:5]
            
            for country, stats in sorted_countries:
                logger.info(f"  {country}: ì´ {stats['total']}ê±´ "
                          f"(H:{stats['high']}, M:{stats['medium']}, "
                          f"L:{stats['low']}, C:{stats['company']})")
        
        if self.stats['errors'] > 0:
            logger.warning(f"âš ï¸ ë°œìƒí•œ ì˜¤ë¥˜: {self.stats['errors']}ê±´")
        
        logger.info("="*70)

    def run_company_monitoring(self, company_cache: CompanyNewsCache):
        """íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤ë§Œ ëª¨ë‹ˆí„°ë§ (3ì‹œê°„ ì£¼ê¸°) - GeminiAnalyzer ë°©ì‹ ì‚¬ìš©"""
        logger.info("\n" + "="*70)
        logger.info("ğŸ¢ íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (3ì‹œê°„ ì£¼ê¸°)")
        logger.info("="*70)
        
        try:
            # 1. íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘
            company_news = self.collect_company_news_only()
            
            if not company_news:
                logger.info("â„¹ï¸ ìˆ˜ì§‘ëœ íšŒì‚¬ ë‰´ìŠ¤ ì—†ìŒ")
                return True
            
            logger.info(f"ğŸ“° {len(company_news)}ê±´ì˜ íšŒì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘")
            
            # 2. ì™„ì „ ì¤‘ë³µ ì œê±° (í•´ì‹œ ê¸°ë°˜)
            hash_filtered_news = []
            for news in company_news:
                if company_cache.is_new_news(news.news_hash):
                    hash_filtered_news.append(news)
                    company_cache.add_news(news.news_hash)
                else:
                    logger.debug(f"  âœ— í•´ì‹œ ì¤‘ë³µ: {news.title[:50]}...")
            
            if not hash_filtered_news:
                logger.info("â„¹ï¸ ëª¨ë“  ë‰´ìŠ¤ê°€ í•´ì‹œ ì¤‘ë³µ (ì™„ì „ ë™ì¼)")
                return True
            
            logger.info(f"ğŸ“‹ í•´ì‹œ ì¤‘ë³µ ì œê±° í›„: {len(hash_filtered_news)}ê±´")
            
            # 3. AI ê¸°ë°˜ ì˜ë¯¸ì  ì¤‘ë³µ ì œê±° (ê¸°ì¡´ ë‰´ìŠ¤ì™€ ë¹„êµ)
            existing_news = company_cache.get_recent_news_for_comparison(days=7)
            
            # GeminiAnalyzerì˜ ì¤‘ë³µ ì œê±° ë°©ì‹ ì‚¬ìš©
            unique_news = self.analyzer.remove_company_duplicates(
                hash_filtered_news, 
                existing_news
            )
            
            if not unique_news:
                logger.info("â„¹ï¸ ëª¨ë“  ë‰´ìŠ¤ê°€ ì˜ë¯¸ì  ì¤‘ë³µ (ê°™ì€ ì‚¬ê±´)")
                company_cache.save_cache()
                company_cache.save_recent_news()
                return True
            
            logger.info(f"ğŸ†• {len(unique_news)}ê±´ì˜ ì§„ì§œ ìƒˆë¡œìš´ íšŒì‚¬ ë‰´ìŠ¤ ë°œê²¬")
            
            # 4. ìƒˆë¡œìš´ ë‰´ìŠ¤ë“¤ ê°„ì˜ ì¤‘ë³µ ì œê±° (ì„œë¡œ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ì˜¨ ê°™ì€ ì‚¬ê±´)
            final_unique_news = self.analyzer.remove_duplicates(unique_news)
            
            # 5. AI ë¦¬ìŠ¤í¬ ë¶„ì„
            analyzed_news = self.analyzer.analyze_risk_batch(final_unique_news)
            
            # 6. ë²ˆì—­ ë° ìš”ì•½
            final_news = self.analyzer.summarize_and_translate(analyzed_news)
            
            # 7. ì²˜ë¦¬ëœ ë‰´ìŠ¤ë¥¼ ìµœê·¼ ë‰´ìŠ¤ ëª©ë¡ì— ì¶”ê°€
            for news in final_news:
                company_cache.add_recent_news(news)
            
            # 8. ë¦¬ìŠ¤í¬ ë ˆë²¨ë³„ ë¶„ë¥˜
            high_risk = [n for n in final_news if n.risk_level == 'HIGH']
            medium_risk = [n for n in final_news if n.risk_level == 'MEDIUM']
            low_risk = [n for n in final_news if n.risk_level == 'LOW']
            
            # 9. ì´ë©”ì¼ ë°œì†¡ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            if high_risk and self.email_config['recipients']:
                high_risks = [n for n in high_risk if 'RISK:' in n.risk_category]
                high_opportunities = [n for n in high_risk if 'OPPORTUNITY:' in n.risk_category]
                
                subject_parts = []
                if high_risks:
                    subject_parts.append(f"ìœ„í—˜ {len(high_risks)}ê±´")
                if high_opportunities:
                    subject_parts.append(f"ê¸°íšŒ {len(high_opportunities)}ê±´")
                
                subject = f"[ì•Œë¦¼] ì‚¼ì„±ë¬¼ì‚° - {' / '.join(subject_parts)} - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                
                html_content = self.create_urgent_company_report(high_risk, report_type='urgent')
                self.send_email_to_recipients(html_content, subject, self.email_config['recipients'])
                
                logger.info(f"ğŸ“§ ê¸´ê¸‰ ì•Œë¦¼ ë°œì†¡ (ìœ„í—˜: {len(high_risks)}ê±´, ê¸°íšŒ: {len(high_opportunities)}ê±´)")
            
            # 10. ê´€ë¦¬ì ì „ì²´ ë¦¬í¬íŠ¸
            if final_news and self.email_config.get('admin_email'):
                html_content_admin = self.create_urgent_company_report(final_news, report_type='admin')
                
                # í†µê³„ ìƒì„±
                high_opp = len([n for n in final_news if n.risk_level == 'HIGH' and 'OPPORTUNITY:' in n.risk_category])
                high_risk_count = len([n for n in final_news if n.risk_level == 'HIGH' and 'RISK:' in n.risk_category])
                med_opp = len([n for n in final_news if n.risk_level == 'MEDIUM' and 'OPPORTUNITY:' in n.risk_category])
                med_risk = len([n for n in final_news if n.risk_level == 'MEDIUM' and 'RISK:' in n.risk_category])
                low_opp = len([n for n in final_news if n.risk_level == 'LOW' and 'OPPORTUNITY:' in n.risk_category])
                low_risk_count = len([n for n in final_news if n.risk_level == 'LOW' and 'RISK:' in n.risk_category])
                
                risk_summary = []
                if high_opp + high_risk_count > 0:
                    risk_summary.append(f"HIGH(ìœ„í—˜{high_risk_count}/ê¸°íšŒ{high_opp})")
                if med_opp + med_risk > 0:
                    risk_summary.append(f"MED(ìœ„í—˜{med_risk}/ê¸°íšŒ{med_opp})")
                if low_opp + low_risk_count > 0:
                    risk_summary.append(f"LOW(ìœ„í—˜{low_risk_count}/ê¸°íšŒ{low_opp})")
                
                subject_admin = f"[ê´€ë¦¬ì] ì‚¼ì„±ë¬¼ì‚° - {' / '.join(risk_summary) if risk_summary else 'ìƒˆ ë‰´ìŠ¤ ì—†ìŒ'} - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                
                self.send_email_to_recipients(html_content_admin, subject_admin, [self.email_config['admin_email']])
                logger.info(f"ğŸ“§ ê´€ë¦¬ì ì „ì²´ ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ (ì „ì²´ {len(final_news)}ê±´)")
            
            # 11. ìºì‹œ ì €ì¥
            company_cache.save_cache()
            company_cache.save_recent_news()
            
            # í†µê³„ ë¡œê·¸
            logger.info("\nğŸ“Š ëª¨ë‹ˆí„°ë§ ê²°ê³¼:")
            logger.info(f"  - HIGH RISK: {len(high_risk)}ê±´ {'(ê¸´ê¸‰ì•Œë¦¼ ë°œì†¡)' if high_risk else ''}")
            logger.info(f"  - MEDIUM RISK: {len(medium_risk)}ê±´")
            logger.info(f"  - LOW RISK: {len(low_risk)}ê±´")
            
            logger.info("âœ… íšŒì‚¬ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"íšŒì‚¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            return False

    def collect_company_news_only(self) -> List[NewsItem]:
        """íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤ë§Œ ìˆ˜ì§‘ (AI ê¸°ë°˜ í•„í„°ë§)"""
        all_news = []
        
        logger.info("\nğŸ¢ íšŒì‚¬ í‚¤ì›Œë“œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (AI í•„í„°ë§)")
        
        for idx, keyword in enumerate(self.company_keywords, 1):
            logger.info(f"[{idx}/{len(self.company_keywords)}] {keyword}")
            
            # ë” ë„“ì€ ë²”ìœ„ë¡œ ì´ˆê¸° ê²€ìƒ‰ (í•„í„°ë§ì€ AIê°€ ì²˜ë¦¬)
            query = f'"{keyword}"'
            
            try:
                params = {
                    "api_key": self.serpapi_key,
                    "engine": "google_news",
                    "q": query,
                    "when": "7d",
                    "gl": "us",  # ê¸€ë¡œë²Œ ê´€ì 
                    "hl": "en"
                }
                
                search = self.GoogleSearch(params)
                response = search.get_dict()
                self.stats['api_calls'] += 1
                
                if "news_results" in response:
                    company_news = []
                    ai_evaluated = 0
                    ai_accepted = 0
                    
                    for item in response["news_results"][:20]:  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ AI í•„í„°ë§
                        # ë‚ ì§œ ì²´í¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                        date_str = item.get('date', '')
                        if not self._is_within_days(date_str, 7):
                            continue
                        
                        # NewsItem ìƒì„±
                        news_item = NewsItem(
                            title=item.get('title', ''),
                            date=date_str,
                            source=item.get('source', {}).get('name', 'Unknown'),
                            snippet=item.get('snippet', ''),
                            link=item.get('link', ''),
                            country="Global",
                            country_ko="í•´ì™¸",
                            country_code="global_samsung",
                            thumbnail=item.get('thumbnail', ''),
                            search_type='company_global',
                            collected_at=datetime.now().isoformat()
                        )
                        
                        # AI ê¸°ë°˜ ê´€ë ¨ì„± í‰ê°€
                        ai_evaluated += 1
                        is_relevant, reason = self.analyzer.evaluate_company_news_relevance(
                            news_item, keyword
                        )
                        
                        if is_relevant:
                            company_news.append(news_item)
                            ai_accepted += 1
                            logger.debug(f"  âœ“ AI ìŠ¹ì¸: {news_item.title[:50]}...")
                        else:
                            logger.debug(f"  âœ— AI ì œì™¸: {news_item.title[:50]}... ({reason[:50]})")
                        
                        # ìµœëŒ€ 15ê±´ë§Œ ìˆ˜ì§‘ (AI í•„í„°ë§ í›„)
                        if len(company_news) >= 15:
                            break
                        
                        # API ê³¼ë¶€í•˜ ë°©ì§€
                        if ai_evaluated % 10 == 0:
                            time.sleep(0.5)
                    
                    logger.info(f"  - {keyword}: AI í‰ê°€ {ai_evaluated}ê±´ â†’ ìŠ¹ì¸ {ai_accepted}ê±´ â†’ ìµœì¢… {len(company_news)}ê±´")
                    all_news.extend(company_news)
                    self.stats['news_collected'] += len(company_news)
                    
            except Exception as e:
                logger.error(f"íšŒì‚¬ í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜ ({keyword}): {e}")
                self.stats['errors'] += 1
            
            time.sleep(1)
        
        # í•œêµ­ ë¯¸ë””ì–´ ê²€ìƒ‰ë„ AI ê¸°ë°˜ìœ¼ë¡œ ì „í™˜
        logger.info("\nğŸ‡°ğŸ‡· í•œêµ­ ì–¸ë¡  ë‚´ íšŒì‚¬ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ (AI í•„í„°ë§)")
        for site in self.korean_media.get('sites', []):
            if not site.get('active', False):
                continue
            
            for term in self.korean_media.get('search_terms', []):
                query = f'{site["selector"]} "{term}"'
                logger.info(f"  - {site['name']}: {term}")
                
                news = self.search_news(
                    query=query,
                    country_code='kr',
                    country_name='Korea',
                    search_type='web'
                )
                
                # AI ê¸°ë°˜ í•„í„°ë§
                filtered_news = []
                for item in news:
                    is_relevant, reason = self.analyzer.evaluate_company_news_relevance(
                        item, term
                    )
                    
                    if is_relevant:
                        item.country = "Samsung C&T"
                        item.country_ko = "ì‚¼ì„±ë¬¼ì‚°"
                        item.country_code = "samsung"
                        filtered_news.append(item)
                        logger.debug(f"  âœ“ í•œêµ­ ë‰´ìŠ¤ í¬í•¨: {item.title[:30]}...")
                
                logger.info(f"    â†’ {len(news)}ê±´ ì¤‘ {len(filtered_news)}ê±´ ì„ íƒ")
                all_news.extend(filtered_news)
                time.sleep(1)
        
        logger.info(f"\nâœ… íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤ {len(all_news)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ (AI í•„í„°ë§)")
        return all_news

    def create_urgent_company_report(self, news_list: List[NewsItem], report_type: str = 'urgent') -> str:
        """ê¸´ê¸‰ íšŒì‚¬ ë‰´ìŠ¤ ì´ë©”ì¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        # ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒ ë¶„ë¥˜ (OPPORTUNITY êµ¬ë¶„ ì¶”ê°€)
        high_risks = [n for n in news_list if n.risk_level == 'HIGH' and 'RISK:' in n.risk_category]
        high_opportunities = [n for n in news_list if n.risk_level == 'HIGH' and 'OPPORTUNITY:' in n.risk_category]
        medium_risks = [n for n in news_list if n.risk_level == 'MEDIUM' and 'RISK:' in n.risk_category]
        medium_opportunities = [n for n in news_list if n.risk_level == 'MEDIUM' and 'OPPORTUNITY:' in n.risk_category]
        low_risks = [n for n in news_list if n.risk_level == 'LOW' and 'RISK:' in n.risk_category]
        low_opportunities = [n for n in news_list if n.risk_level == 'LOW' and 'OPPORTUNITY:' in n.risk_category]
        
        total_news = len(news_list)
        
        # ë¦¬í¬íŠ¸ íƒ€ì…ì— ë”°ë¥¸ ì„¤ì •
        if report_type == 'admin':
            header_color = '#17a2b8'  # ì²­ë¡ìƒ‰ (ê´€ë¦¬ììš©)
            header_title = "ğŸ“Š ì‚¼ì„±ë¬¼ì‚° ì „ì²´ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ (ê´€ë¦¬ì)"
            show_alert = True
        else:
            if high_opportunities and not high_risks:
                header_color = '#28a745'  # ë…¹ìƒ‰
                header_title = "ğŸ¯ ì‚¼ì„±ë¬¼ì‚° ì£¼ìš” ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ"
                show_alert = False
            elif high_risks:
                header_color = '#dc3545'  # ë¹¨ê°„ìƒ‰
                header_title = "âš ï¸ ì‚¼ì„±ë¬¼ì‚° ê´€ë ¨ ê¸´ê¸‰ ë‰´ìŠ¤"
                show_alert = True
            else:
                header_color = '#6c757d'
                header_title = "ğŸ“° ì‚¼ì„±ë¬¼ì‚° ê´€ë ¨ ë‰´ìŠ¤"
                show_alert = False
        
        html = f"""<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>ì‚¼ì„±ë¬¼ì‚° ê´€ë ¨ ë‰´ìŠ¤</title>
        </head>
        <body style="margin: 0; padding: 0; font-family: 'Malgun Gothic', Arial, sans-serif; background-color: #f4f4f4;">
            <div style="max-width: 700px; margin: 0 auto; background-color: #ffffff; border-radius: 8px; overflow: hidden; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
                <div style="background-color: {header_color}; padding: 25px; text-align: center;">
                    <h1 style="color: #ffffff; margin: 0; font-size: 26px;">{header_title}</h1>
                    <p style="color: #ffffff; margin: 10px 0 0 0; font-size: 14px;">
                        {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')} | {total_news}ê±´ ê°ì§€
                    </p>
                </div>
                
                <div style="padding: 25px;">"""
        
        # ì•Œë¦¼ ë°•ìŠ¤ (ê´€ë¦¬ì ëª¨ë“œëŠ” í•­ìƒ í‘œì‹œ)
        if report_type == 'admin' or (show_alert and high_risks):
            if report_type == 'admin':
                alert_message = f"ì „ì²´ {total_news}ê±´ì˜ ë‰´ìŠ¤ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                alert_message = f"{len(high_risks)}ê±´ì˜ ìœ„í—˜ ì‚¬í•­ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            html += f"""
                    <div style="background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 15px; margin-bottom: 20px;">
                        <p style="margin: 0; color: #856404;">
                            <strong>ì•Œë¦¼:</strong> {alert_message}
                        </p>
                        <p style="margin: 5px 0 0 0; color: #856404; font-size: 13px;">
                            ìœ„í—˜ HIGH: {len(high_risks)}ê±´ | ê¸°íšŒ HIGH: {len(high_opportunities)}ê±´ | 
                            ìœ„í—˜ MED: {len(medium_risks)}ê±´ | ê¸°íšŒ MED: {len(medium_opportunities)}ê±´ | 
                            ìœ„í—˜ LOW: {len(low_risks)}ê±´ | ê¸°íšŒ LOW: {len(low_opportunities)}ê±´
                        </p>
                    </div>"""
        
        news_counter = 1
        
        # HIGH OPPORTUNITY ë‰´ìŠ¤
        if high_opportunities:
            html += f"""
                    <h2 style="color: #28a745; margin: 25px 0 15px 0; font-size: 20px; border-bottom: 2px solid #28a745; padding-bottom: 5px;">
                        ğŸ’ HIGH OPPORTUNITY ({len(high_opportunities)})
                    </h2>"""
            
            for news in high_opportunities:
                html += self._create_urgent_news_item(news, news_counter, '#28a745')
                news_counter += 1
        
        # HIGH RISK ë‰´ìŠ¤
        if high_risks:
            html += f"""
                    <h2 style="color: #dc3545; margin: 25px 0 15px 0; font-size: 20px; border-bottom: 2px solid #dc3545; padding-bottom: 5px;">
                        ğŸ”´ HIGH RISK ({len(high_risks)})
                    </h2>"""
            
            for news in high_risks:
                html += self._create_urgent_news_item(news, news_counter, '#dc3545')
                news_counter += 1
        
        # ê´€ë¦¬ì ëª¨ë“œì—ì„œë§Œ MEDIUM, LOW í¬í•¨
        if report_type == 'admin':
            # MEDIUM OPPORTUNITY
            if medium_opportunities:
                html += f"""
                        <h2 style="color: #17a2b8; margin: 25px 0 15px 0; font-size: 20px; border-bottom: 2px solid #17a2b8; padding-bottom: 5px;">
                            ğŸ’¼ MEDIUM OPPORTUNITY ({len(medium_opportunities)})
                        </h2>"""
                
                for news in medium_opportunities:
                    html += self._create_urgent_news_item(news, news_counter, '#17a2b8')
                    news_counter += 1
            
            # MEDIUM RISK
            if medium_risks:
                html += f"""
                        <h2 style="color: #ffc107; margin: 25px 0 15px 0; font-size: 20px; border-bottom: 2px solid #ffc107; padding-bottom: 5px;">
                            ğŸŸ¡ MEDIUM RISK ({len(medium_risks)})
                        </h2>"""
                
                for news in medium_risks:
                    html += self._create_urgent_news_item(news, news_counter, '#ffc107')
                    news_counter += 1
            
            # LOW OPPORTUNITY
            if low_opportunities:
                html += f"""
                        <h2 style="color: #20c997; margin: 25px 0 15px 0; font-size: 20px; border-bottom: 2px solid #20c997; padding-bottom: 5px;">
                            ğŸ“ˆ LOW OPPORTUNITY ({len(low_opportunities)})
                        </h2>"""
                
                for news in low_opportunities:
                    html += self._create_urgent_news_item(news, news_counter, '#20c997')
                    news_counter += 1
            
            # LOW RISK
            if low_risks:
                html += f"""
                        <h2 style="color: #6c757d; margin: 25px 0 15px 0; font-size: 20px; border-bottom: 2px solid #6c757d; padding-bottom: 5px;">
                            âšª LOW RISK ({len(low_risks)})
                        </h2>"""
                
                for news in low_risks:
                    html += self._create_urgent_news_item(news, news_counter, '#6c757d')
                    news_counter += 1
        
        html += """
                </div>
                <div style="background-color: #f8f9fa; padding: 20px; text-align: center; border-top: 1px solid #dee2e6;">
                    <p style="margin: 0; color: #666; font-size: 12px;">
                        Samsung C&T Risk Monitoring System<br>
                        3ì‹œê°„ ì£¼ê¸° ìë™ ëª¨ë‹ˆí„°ë§
                    </p>
                </div>
            </div>
        </body>
        </html>"""
        return html

    def _create_urgent_news_item(self, news: NewsItem, idx: int, border_color: str) -> str:
        """ê°œë³„ ë‰´ìŠ¤ ì•„ì´í…œ HTML ìƒì„±"""
        title_to_display = news.ai_title_ko if news.ai_title_ko else news.title
        
        # ì¹´í…Œê³ ë¦¬ì—ì„œ ê¸°íšŒ/ë¦¬ìŠ¤í¬ êµ¬ë¶„
        is_opportunity = 'OPPORTUNITY:' in news.risk_category
        
        # ì¹´í…Œê³ ë¦¬ í‘œì‹œ ì •ë¦¬
        category_display = news.risk_category.replace('RISK: ', '').replace('OPPORTUNITY: ', '')
        
        # ê¸°íšŒ/ìœ„í—˜ì— ë”°ë¥¸ ë¼ë²¨ ë° ë°°ê²½ìƒ‰
        if is_opportunity:
            score_label = "ì¤‘ìš”ë„ ì ìˆ˜"
            category_label = "ê¸°íšŒ ìœ í˜•"
            bg_color = "#f0f9ff"  # ì—°í•œ íŒŒë€ìƒ‰ ë°°ê²½
        else:
            score_label = "ë¦¬ìŠ¤í¬ ì ìˆ˜"
            category_label = "ìœ„í—˜ ìœ í˜•"
            bg_color = "#f8f9fa"  # ê¸°ì¡´ íšŒìƒ‰ ë°°ê²½
        
        return f"""
            <div style="border: 1px solid #dee2e6; border-left: 5px solid {border_color}; padding: 20px; margin-bottom: 20px; background-color: {bg_color};">
                <h3 style="margin: 0 0 10px 0; color: #333; font-size: 18px;">
                    {idx}. {title_to_display}
                </h3>
                <div style="margin: 10px 0; color: #666; font-size: 13px;">
                    ğŸ“° {news.source} | ğŸ“… {news.date}
                </div>
                <div style="margin: 15px 0; padding: 10px; background-color: #ffffff; border-radius: 4px;">
                    <strong style='color: {border_color};'>{score_label}: {news.risk_score:.0f}</strong> | 
                    {category_label}: {category_display}
                </div>
                <div style="margin: 15px 0; padding: 10px; background-color: #ffffff; border-radius: 4px;">
                    <strong>AI ìš”ì•½:</strong><br>
                    <p style="margin: 5px 0; color: #333; line-height: 1.6;">
                        {news.ai_summary_ko or 'ìš”ì•½ ìƒì„± ì¤‘...'}
                    </p>
                </div>
                <a href="{news.link}" style="display: inline-block; margin-top: 10px; padding: 10px 20px; background-color: #007bff; color: white; text-decoration: none; border-radius: 4px;">
                    ì›ë¬¸ ë³´ê¸° â†’
                </a>
            </div>"""

    def send_urgent_email(self, html_content: str, subject: str) -> bool:
        """ê¸´ê¸‰ ì´ë©”ì¼ ì „ì†¡"""
        try:
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.email_config['sender_email']
            msg['To'] = ', '.join(self.email_config['recipients'])
            
            html_part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(html_part)
            
            with smtplib.SMTP(self.email_config['smtp_server'], self.email_config['smtp_port']) as server:
                server.starttls()
                server.login(self.email_config['sender_email'], self.email_config['sender_password'])
                server.send_message(msg)
                
            logger.info(f"ğŸ“§ ê¸´ê¸‰ ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False

    def send_email_to_recipients(self, html_content: str, subject: str, recipients: List[str]) -> bool:
        """íŠ¹ì • ìˆ˜ì‹ ìë“¤ì—ê²Œ ì´ë©”ì¼ ì „ì†¡"""
        try:
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.email_config['sender_email']
            msg['To'] = ', '.join(recipients)
            
            html_part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(html_part)
            
            with smtplib.SMTP(self.email_config['smtp_server'], self.email_config['smtp_port']) as server:
                server.starttls()
                server.login(self.email_config['sender_email'], self.email_config['sender_password'])
                server.send_message(msg)
                
            logger.info(f"ğŸ“§ ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ: {', '.join(recipients)}")
            return True
            
        except Exception as e:
            logger.error(f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False

    def run(self, test_mode=False):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        logger.info("\n" + "="*70)
        logger.info("ğŸš€ AI ê¸°ë°˜ ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        logger.info("="*70)
        
        try:
            # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
            logger.info("\nğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ë‹¨ê³„")
            all_news = self.collect_all_news()
            logger.info(f"âœ… ì´ {len(all_news)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # 2. AI ê¸°ë°˜ ì¤‘ë³µ ì œê±°
            logger.info("\nğŸ” AI ì¤‘ë³µ ì œê±° ë‹¨ê³„")
            unique_news = self.analyzer.remove_duplicates(all_news)
            self.stats['news_after_dedup'] = len(unique_news)
            logger.info(f"âœ… ì¤‘ë³µ ì œê±° í›„ {len(unique_news)}ê±´")
            
            # 3. AI ë¦¬ìŠ¤í¬ ë¶„ì„
            logger.info("\nğŸ¤– AI ë¦¬ìŠ¤í¬ ë¶„ì„ ë‹¨ê³„")
            analyzed_news = self.analyzer.analyze_risk_batch(unique_news)
            self.stats['news_analyzed'] = len(analyzed_news)
            
            # 4. ìš”ì•½ ë° ë²ˆì—­
            logger.info("\nğŸ“ ìš”ì•½ ë° ë²ˆì—­ ë‹¨ê³„")
            final_news = self.analyzer.summarize_and_translate(analyzed_news)
            
            # 5. í†µê³„ ì—…ë°ì´íŠ¸
            self.update_risk_statistics(final_news)
            
            # 6. ë¦¬í¬íŠ¸ ìƒì„±
            logger.info("\nğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± ë‹¨ê³„")
            html_content = self.create_ai_html_report(final_news)
            
            # 7. íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            html_file = f'ai_risk_report_{timestamp}.html'
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            # 8. ì´ë©”ì¼ ì „ì†¡
            if test_mode and self.email_config.get('admin_email'):
                # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ê´€ë¦¬ìì—ê²Œë§Œ ì „ì†¡
                logger.info("\nğŸ“§ í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ê´€ë¦¬ìì—ê²Œë§Œ ì´ë©”ì¼ ì „ì†¡...")
                
                # subject ë³€ìˆ˜ ì •ì˜ (ëˆ„ë½ëœ ë¶€ë¶„)
                high_risk_count = len([n for n in final_news if n.risk_level == 'HIGH'])
                if high_risk_count > 0:
                    subject = f"[í…ŒìŠ¤íŠ¸] ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ - âš ï¸ HIGH RISK {high_risk_count}ê±´ - {datetime.now().strftime('%Y-%m-%d')}"
                else:
                    subject = f"[í…ŒìŠ¤íŠ¸] ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ - ì •ìƒ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ - {datetime.now().strftime('%Y-%m-%d')}"
                
                recipients = [self.email_config['admin_email']]
                email_sent = self.send_email_to_recipients(
                    html_content, 
                    subject,  # ì´ì œ ì •ì˜ë¨
                    recipients
                )
            
                if email_sent:
                    logger.info("âœ… í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ (ê´€ë¦¬ì)")
                else:
                    logger.error("âŒ í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨")
                    
            elif self.email_config['sender_email'] and self.email_config['recipients']:
                logger.info("\nğŸ“§ ì´ë©”ì¼ ì „ì†¡ ì‹œì‘...")
                email_sent = self.send_email_report(html_content, final_news)
                if email_sent:
                    logger.info("âœ… ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ")
                else:
                    logger.error("âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨")
            else:
                logger.warning("âš ï¸ ì´ë©”ì¼ ì„¤ì •ì´ ì—†ì–´ ì „ì†¡í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                email_sent = False
            
            # 9. ê²°ê³¼ ì¶œë ¥
            self._print_detailed_stats()
            
            return {
                'success': True,
                'stats': self.stats,
                'files': {'html': html_file}
            }
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {'success': False, 'error': str(e)}


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='AI ê¸°ë°˜ ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§')
    parser.add_argument('--mode', 
                       choices=['test', 'daily', 'company', 'schedule'],
                       default='test',
                       help='ì‹¤í–‰ ëª¨ë“œ: test(í…ŒìŠ¤íŠ¸-1íšŒ), daily(ì¼ì¼ì „ì²´), company(íšŒì‚¬ë§Œ), schedule(ìŠ¤ì¼€ì¤„ë§)')
    parser.add_argument('--config', 
                       default='monitoring_config.json', 
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    args = parser.parse_args()
    
    try:
        monitor = AIRiskMonitoringSystem(args.config)
        
        if args.mode == 'test':
            logger.info("\nğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ì „ì²´ ëª¨ë‹ˆí„°ë§ 1íšŒ ì‹¤í–‰")
            result = monitor.run(test_mode=True)
            
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œë„ ëª…ì‹œì ìœ¼ë¡œ ì´ë©”ì¼ ì „ì†¡ í™•ì¸
            if result['success']:
                logger.info("âœ… í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰ ì™„ë£Œ")
                if monitor.email_config['sender_email'] and monitor.email_config['recipients']:
                    logger.info("ğŸ“§ ì´ë©”ì¼ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ìë™ ì „ì†¡ë©ë‹ˆë‹¤.")
                else:
                    logger.warning("âš ï¸ ì´ë©”ì¼ ì„¤ì •ì´ ì—†ì–´ ì „ì†¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        elif args.mode == 'daily':
            logger.info("\nğŸ“Š ì¼ì¼ ì „ì²´ ëª¨ë‹ˆí„°ë§ ëª¨ë“œ")
            monitor.run_daily_monitoring()
            
        elif args.mode == 'company':
            logger.info("\nğŸ¢ íšŒì‚¬ ì „ìš© ëª¨ë‹ˆí„°ë§ ëª¨ë“œ")
            company_cache = CompanyNewsCache()
            monitor.run_company_monitoring(company_cache)
            
        elif args.mode == 'schedule':
            logger.info("\nâ° ìŠ¤ì¼€ì¤„ ëª¨ë“œ ì‹œì‘")
            logger.info("ì„¤ì •ëœ ìŠ¤ì¼€ì¤„:")
            logger.info("  - ë§¤ì¼ ì˜¤ì „ 7ì‹œ: ì „ì²´ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§")
            logger.info("  - 3ì‹œê°„ë§ˆë‹¤: íšŒì‚¬ ê´€ë ¨ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§")
            logger.info("Ctrl+Cë¡œ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")
            
            company_cache = CompanyNewsCache()
            
            # ìŠ¤ì¼€ì¤„ ì„¤ì •
            schedule.every().day.at("07:00").do(monitor.run_daily_monitoring)
            schedule.every(3).hours.do(monitor.run_company_monitoring, company_cache)
            
            # ì‹œì‘ ì‹œ ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰ (íšŒì‚¬ ëª¨ë‹ˆí„°ë§ë§Œ)
            logger.info("ğŸš€ ì´ˆê¸° ì‹¤í–‰ ì‹œì‘...")
            monitor.run_company_monitoring(company_cache)
            
            # ìŠ¤ì¼€ì¤„ ë£¨í”„ ì‹¤í–‰
            logger.info("\nâ³ ìŠ¤ì¼€ì¤„ëŸ¬ ëŒ€ê¸° ì¤‘...")
            while True:
                schedule.run_pending()
                time.sleep(60)
            
    except KeyboardInterrupt:
        logger.info("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())


if __name__ == "__main__":
    main()